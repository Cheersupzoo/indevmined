---
title: LLM & Generative AI สำหรับคนขับ
language: th
language-en-link: ""
published: 2024-11-02
categories: learning
keywords:
  - GenAI
extracted: ""
reading-time: 1
draft: false
---
![กล่องดำ](Pasted%20image%2020241113151615.png)
กล่องดำ

**คนขับ**? **คนขับ**ในที่นี้ไม่ใช่**คนขับรถ**แต่อย่างไร เพราะคุณห้ามเล่นมือถือขณะขับรถ

แต่**คนขับ**ในที่นี้ เราหมายถึงคนที่ต้องการขับเคลื่อนการนำ Gen AI มาใช้ในชีวิตประจำวัน ในบริษัท ในองค์กร

แต่ถ้าจะเปรียบเปรยกับการเดินทาง ก็อาจจะมองว่า คุณที่อ่านอยู่นี้ คือคนขับรถ คุณรู้จักเส้นทาง และการทำงานของรถยนต์เบื้องต้น เพียงพอให้คุณสามารถพาตัวเองไปถึงปลายทางได้

คุณไม่ใช่ผู้โดยสารที่สามารถเพลิดเพลินไปกับเส้นทางได้ คุณต้องมีสติเวลาขับรถ แต่คุณก็ไม่ได้ชำนาญเหมือนช่างที่ซ่อมรถคุณเมื่อมีปัญหาได้

คุณ **คนขับ** อยากใช้ Gen AI ให้มีประสิทธิภาพ อยากใช้ให้เป็นในแบบที่ควรเป็น และไม่จำเป็นต้องมีความรู้แบบคนเขียนโปรแกรม หรือนักวิจัย ขอเพียงก็อปวางใน ChatGPT และได้คำตอบที่ถูกใจ ทำซ้ำได้ ก็เพียงพอแล้ว ที่สำคัญ เราจะพาไปดูว่า ต่อให้ไม่ต้องรู้ศัพท์เทคนิคเฉพาะเท่ๆ อย่าง Chain of Though, Few-shots Prompting ก็สามารถเขียน Prompt ที่ดีได้

หากคิดว่า คุณคือ**คนขับ** ก็ไปกันต่อเลย

> คำศัพท์ที่นิยมใช้ในบทความนี้
> - **Generative AI** หรือ **Gen AI** - นิยมมาในรูปแบบแชทบอท ที่เรานิยมใช้ผ่านเว็ป chat.openai.com หรือ ChatGPT หรือ Claude.ai
> 	- เวลากล่าวถึง **Gen AI** ให้นึกถึง ChatGPT
> - **Large Language Model** หรือ **LLM** - โมเดลภาษาขนาดใหญ่ มีความยืดหยุ่นอย่างมาก สามารถนำมาทำงานได้หลากหลาย เช่น การตอบคำถาม การแปลเอกสาร การสรุปความ เป็นต้น นิยมใช้เป็นเบื้องหลังการทำงานให้ Gen AI เช่น ChatGPT มีโมเดล GPT-4o และ Claude.ai มีโมเดล Claude Sonnet 3.5
> 	- เวลากล่าวถึง **LLM** ให้นึกถึง GPT-4o
> - **Prompt** - ในที่นี้คือข้อความที่เราส่งให้ LLM ซึ่งเราจะเปรียบเป็น **คำสั่ง** ไว้สั่งการ LLM

ปัญหาที่นิยมพบเจอบ่อยๆ เวลาใช้ Gen AI ก็หนีไม่พ้นโมเดลเพ้อบ้าง หลอนบ้าง หรือไม่ก็มั่วบ้าง แต่หลายครั้งก็ให้ผลลัทธ์ที่ดี และเป็นที่พึงพอใจ ทำไมกันละ ถ้าอยากรู้ ก็มาเริ่มด้วยการแยกชิ้นส่วนของ ChatGPT พาไปไขความลับของการใช้ Generative AI ในบทความนี้กัน
## แยกชิ้นส่วน Generative AI

เมื่อคุณมาถึงจุดที่อยากปรับจูนการใช้งาน Gen AI ให้ละเอียดขึ้น ก็หนีไม่พ้นจุดที่ต้องเริ่มทำความเข้าใจองค์ประกอบภายในของเครื่องมือที่กำลังใช้อยู่

> ทำไมต้องรู้ ก็เพราะหลายครั้งที่ Gen AI ตอบผิด อาจจะไม่ใช้ความผิดของ LLM แต่เป็นเพราะองค์กอบอื่นที่เชื่อมกันอยู่ ยังไงละ

เครื่องมือตัวที่เราใช้ประจำอย่าง ChatGPT นั้น เป็นเปลือกนอกสุดที่คนทั่วไปเห็น ส่วนนี้นิยมเป็นแชทบอท พูดคุยกับเรา สร้างขึ้นมาเพื่อโชว์ศักยภาพทั้งหมดที่ LLM พึงจะทำได้

ถ้าหากเราชำแหละ ChatGPT ลงไปหนึ่งขั้น เราจะเจอ

1. LLM เช่น GPT-4o - ส่วนนี้คือองค์ประกอบหลัก ทำหน้าที่รับ **ข้อความ รูป เสียง** และนำไปผลิต **ข้อความ รูป เสียง** เท่านั้น ย้ำว่าแค่หลักๆ แค่ 3 อย่างนี้เท่านั้น (ณ เวลานี้)
2. Function calling - เครื่องมืออื่นๆ ทำหน้าที่เติมเต็มในสิ่งที่ Model ไม่สามารถทำได้ตัวเอง
3. Orchestrator - เครื่องมือหน้าด่าน ทำหน้าที่ตัดสินใจว่าจะทำอะไรกับ ข้อมูลที่คุณส่งให้บอท ที่นิยมในปัจจุบัน คือนำ LLM ที่มีคำสั่งให้เพียงตัดสินใจเท่านั้น และรันคำสั่งตามนั้น

![](Untitled%20Diagram.drawio.svg)
ตัวอย่างโครงสร้าง ChatGPT

เบื้องต้น 3 อย่างตามนี้ จะเห็นได้ว่า LLM ไม่มีมือเป็นของตัวเอง มีเพียงตา หู และปาก ดังนั้นเวลาต้องทำอะไรนอกเหนือจากความสามารถของมัน ก็ต้องพึ่งพาคนอื่นมาช่วย

เพื่อให้เห็นภาพอีกหน่อย เราไปดูตัวอย่าง และวิเคราะห์แต่ละองค์ประกอบกัน

#### ตัวอย่างที่ 1 คุยกับข้อมูลในอดีตของคุณ
สมมุติว่าเคยคุยกับ ChatGPT มาเป็นเวลาหลายเดือน ตัว ChatGPT ก็จะมีการจัดเก็บข้อมูลเหล่านั้นให้ดึงมาใช้งานได้ แล้วปัจจุบันคุณถามไปว่า "สีโปรดของฉันคือสีอะไร" สิ่งที่ ChatGPT จะทำในเบื้องหลังจะเป็นดังนี้

1. Orchestrator จะตัดสินใจว่าคำถามของคุณเกี่ยวของกับข้อมูลส่วนตัวคุณ ถ้าเกี่ยวสร้างคำสั่งให้ Function calling ไปดึงข้อความที่เกี่ยวข้องกับ "ความชื่นชอบ" มาทั้งหมด 10 อันล่าสุด
2. Function calling ที่ถูกเรียก ดึงผลลัพธ์ แล้วส่งกลับไปให้ Orchestrator
3. Orchestrator ทำการประกอบร่างข้อความเข้าด้วยกัน ประกอบด้วย ข้อความระบบ + ข้อความคำถามของผู้ใช้ + ผลลัพธ์จาก Function calling แล้วส่งไปให้ LLM 
4. LLM คิดคำตอบส่งไปแสดงให้ผู้ใช้

เมื่อรันเสร็จ คุณก็หวังว่ามันตอบถูก ซึ่งจะเป็นไปได้ก็ต่อเมื่อ คุณเคยคุยเรื่องของสีโปรดในอดีต และ!!! Function calling ทำการดึงข้อมูลถูกส่วนนั้นไปให้ LLM ประมวล ดังนั้นจึงมีโอกาสที่ ChatGPT จะตอบผิด หรือมั่วคำตอบขึ้นมา โดยที่ตัวมันเองไม่รู้ตัว

ถ้าเราไปเจาะลึกกันต่อว่าทำไม Function calling ทำการดึงข้อมูลมาผิดได้ ก็ต้องย้อนกลับไปดูว่า Orchestrator ก็มีส่วนที่สร้างคำค้นหาผิด เช่น ข้อความมีความข้องกับ "ความชื่นชอบ" แต่ดันส่งคำค้นหาเป็น "สี" เฉยๆ ผลลัพธ์ที่ได้จาก Function calling เลยกว้างเกิน แล้วตกหล่น "สีที่ชอบไปได้"

#### ตัวอย่างที่ 2 ถามข้อมูลข้อเท็จจริง
คุณหลีกหนีจากโลกข่าวสารมานาน วันหนึ่งเจอคนถึงหมูเด้งเป็นจำนวนมาก เลยอยากรู้ว่า "หมูเด้งคืออะไร" สิ่งที่ ChatGPT จะทำ
1. Orchestrator จะตัดสินใจว่านี้เป็นคำถามทั่วไป ส่งไปให้ LLM ได้เลย
2. LLM คิดคำตอบส่งไปแสดงให้ผู้ใช้

![](Screenshot%202567-11-10%20at%2010.07.30.png)
หมูเด้งคืออะไร

ผลลัพธ์ที่เป็นเช่นนี้ก็เพราะ LLM ของเรามีความรู้ข้อมูลล่าสุดอยู่ที่ เดือน ตุลาคม ปี 2023 ซึ่งเป็นคำตอบที่ถูกต้องที่สุดสำหรับ LLM

แต่ถ้าหากเราเปลี่ยนคำถามเป็น "หมูเด้งคืออะไร ถ้าเสริชจากข่าวในเน็ต" สิ่งที่ ChatGPT จะทำ
1. Orchestrator จะตัดสินใจว่านี้เป็นคำถามที่ต้องการข้อมูลความจริงล่าสุด ควรเสริชเช็คข้อมูลล่าสุด เรียก Function calling ให้เสริชอินเตอร์เน็ตด้วย คำค้นหา "หมูเด้งคืออะไร"
2. Function calling เสริชอินเตอร์เน็ต แล้วส่งผลลัพธ์กลับไปให้ Orchestrator
3. Orchestrator ทำการประกอบร่างข้อความเข้าด้วยกัน ประกอบด้วย ข้อความระบบ + ข้อความคำถามของผู้ใช้ + ผลลัพธ์จาก Function calling แล้วส่งไปให้ LLM 
4. LLM คิดคำตอบส่งไปแสดงให้ผู้ใช้

![](Screenshot%202567-11-10%20at%2010.12.55.png)
หมูเด้งคืออะไร ถ้าเสริชจากข่าวในเน็ต

รอบนี้คำตอบถูกต้องแล้ว ตามบริบทของคนส่วนใหญ่ เวลาเราพูดถึงหมูเด้ง เราหมายถึงลูกฮิปโปแคระ ไม่ใช่อาหาร 

ตัวอย่างนี้ เราพอจะเห็นได้ว่า LLM ตอบดีไม่ดี ก็ขึ้นกับข้อมูลที่ส่งไปให้ เราอยากให้มันตอบข้อมูลล่าสุดได้ เราก็ต้องส่งข้อมูลล่าสุดแนบไปให้ด้วย

#### ตัวอย่างที่ 3 บอกให้บอทเจนรูปภาพ
คุณอยากได้รูปโลโก้เว็บไซด์อันใหม่ เลยไปบอกให้ ChatGPT วาดรูปภาพให้ แล้วก็อธิบายรายละเอียดในรูป ตัวประกอบหลักคือใคร พื้นหลังประกอบไปด้วยอะไร สไตล์ภาพเป็นอย่างไร

บางครั้ง คุณก็จะได้รูปภาพกลับมา ตามที่ต้องการ แต่บางครั้ง คุณกลับได้ AI ตอบกลับมาเป็นข้อความเฉยๆ ไม่มีรูป

ทำไมกันละ เราไปดูขั้นตอนเบื้องหลังกัน

1. Orchestrator จะตัดสินใจว่านี้เป็นคำถาม ต้องการให้วาดรูปภาพให้ หรือเป็นคำบอกกล่าวทั่วไป ถ้าตัดสินใจถูก ก็จะไปเรียก Function calling เครื่องมือ DALL·E 3
2. Function calling - DALL·E 3 วาดรูปภาพขึ้นมา ด้วยคำบรรยายจาก Orchestrator แล้วส่งรูปที่วาดเสร็จกลับไปให้ Orchestrator
3. Orchestrator ส่งต่อรูปภาพไปให้ผู้ใช้ และส่งไปให้ LLM อธิบายรูปภาพนั้น
4. LLM คิดคำบรรยายส่งไปแสดงให้ผู้ใช้

![](Screenshot%202567-11-11%20at%2010.43.41.png)
Create 2d logo image of a hamster working hard

ในตัวอย่างนี้ จะเห็นได้ว่า Orchestrator มีผลกับคำตอบของ ChatGPT อย่างมากว่าจะได้ หรือไม่ได้รูปภาพ

---
เห็นตัวอย่างไป 3 อัน น่าจะทำให้เริ่มเห็นภาพว่า การทำงานแต่ละครั้ง ของ ChatGPT ต้องพี่งองค์ประกอบอะไรบ้าง และงานไหนบ้างที่เป็นหน้าที่ของ LLM เพราะหลังจากนี้ เราจะไปเจาะลึกกันที่ LLM เอาให้เห็นว่าอะไรคือสิ่งที่ LLM เฉยๆทำได้ งานไหนที่ต้องพึ่งพาอย่างอื่นเข้ามาช่วย และเมื่อเจอปัญหาจะได้แก้ได้ตรงจุด

## Large Language Model (LLM)
หลายครั้งที่เราชอบมอง LLM อย่าง GPT-4o เป็นเหมือนกล่องดำ ที่เพียงยัดข้อมูลไปให้มันเยอะๆ แล้วจะได้ ผลลัพธ์ที่ดีออกมา แต่สุดท้ายก็ล้มเหลว และมองว่ายังอีกห่างไกล กว่าเราจะเอามันมาใช้ทำงานได้

แต่ก็มีคนอีกกลุ่มที่ดึงความสามารถของมันออกมาได้ และสร้างเครื่องมือที่เราใช้กันอยู่ทุกวันนี้ ที่เขาทำได้นั้น เพราะความเข้าใจในการทำงานของมัน ดังนั้นเรามาเริ่มที่จุดเดียวกัน เข้าใจ LLM
#### เอาใจเขามาใส่ใจเรา

![](Pasted%20image%2020241119093830.png)
ห้องที่มีเพียงหน้าต่างหนึ่งบาน ไม่มีประตู

เอาใหม่ มองใหม่ ไหนๆ GPT-4o ก็ถูกสอนด้วย ข้อมูลจากเรา คน นี้แหละ และด้วยข้อมูลจำนวนมาก ลองมองซะว่า GPT-4o ก็คือคนคนหนึ่ง ที่มีความฉลาดเทียบเท่ากับคนทั่วไปในแต่ละวงการ แต่เขาฉลาดในทุกด้านเลย ความรู้ของเขากว้างขวางมาก และตระกะความคิดก็ไม่ได้เป็นรองกับใคร แต่!!! เขามีข้อจำกัดอันใหญ่คือ เขาถูกกักขังอยู่ในห้อง ที่มีเพียงหน้าต่างบานเล็กๆ ไว้สำหรับแลกเปลี่ยนข้อมูลกับโลกภายนอก ดังนั้น เขาไม่สามารถออกไปช่วยเหลือใครได้ด้วยตัวเขาเอง ทำได้เพียงส่งข้อความใครคนภายนอกทำให้ เขาไม่สามารถเรียบรู้เรื่องใหม่ได้ด้วยตัวเอง หากจะเรียนรู้ได้ ก็ต้องพึ่งพาคนอื่นให้ช่วยค้นคว้าและส่งต่อข้อมูลเหล่านั้นมา นอกจากนั้น ด้วยความที่เขาเก่งหลายด้าน ก็ทำให้เขามีมุมมองที่แตกต่างไปจากคนทั่วไป เขาจะสามารถมองได้ด้วยมุมมองของช่างภาพ วิศวะกร หมอ นักข่าว ชาวสวน ฯลฯ ในเวลาเดียวกัน สามัญสำนึกเลยดูแปลกไปจากคนทั่วไป บุคลิกของเขาจะเป็นคนตรงๆ ตรงแบบเอาไม้บรรทัดมาตีเส้นเลยเชียว ดังนั้นเราจึงต้องให้ความสำคัญกับการสื่อสารเป็นอย่างยิ่ง แต่อย่างไรจึงจะถ้าว่าสื่อสารได้ดี?

#### การสื่อสาร
<p><img src="Pasted%20image%2020241119100508.png" alt="Communication" width="400" /><span>Communication</span></p>

พอเราเริ่มเข้าใจมุมมองของ LLM ต่อมาเราจะให้เขามาเป็นผู้ช่วยที่ดีให้กับเราได้อย่างไร เราจะทำยังไงให้เขาทำงานได้เต็มประสิทธิภาพ ทั้งหมดนี้ ก็จะมาลงเอยกับ **การสื่อสาร**

ส่งตัวแทน LLM ด้วยน้อง GPT-4o

ในที่นี้เราจะไม่มานั่งคุยว่า เทคนิคการ Prompt มีอะไรบ้าง หรือ Prompt Engineering เขาทำกันอย่างไร กลับกัน เรากำลังมองว่า GPT-4o ก็คือคนคนหนึ่ง เป็นเด็กจบใหม่มากความสามารถ เพิ่งเริ่มงาน ดังนั้นคุณในฐานะหัวหน้า จะทำอย่างไรให้เขาเริ่มงานได้ไวที่สุด ทำยังไงให้เขาทำงานออกมาดี

ปกติแล้วคุณจะทำอย่างไรบ้าง เป็นผมก็ต้องมี Onboarding Process ที่ดี มีเอกสารให้เขาสามารถอ่านแล้วทำตามได้ มีการระบุให้ชัดเจนว่าตำแหน่ง หน้าที่การทำงานครอบคลุมอะไรบ้าง มีการระบุความคาดหวัง มีการสอนงานให้เป็นลำดับขั้นตอน ให้เด็กใหม่นั่งเทียนเอง ก็คาดหวังได้เลยว่างานมีโอกาสเละ

การสื่อสารเองก็มีเทคนิค หรือมีแบบแผนให้ทำตามได้อยู่บ้าง หลายครั้งถ้าสังเกตดีๆ การสื่อสารที่ดีก็เป็นสามัญสำนึก ที่เราใช้โดยเคยชิน ใครที่สื่อสารเก่งก็จะนิยมนำมันไปใช้ ดังนั้น เราค่อยๆ ยกตัวอย่างเหตุการณ์ แล้วตามด้วยเทคนิคการสื่อสารกัน

##### ตัวอย่าง 1
นึกย้อนกลับไปเวลาเรายังเด็ก ต้องทำรายงานส่งอาจารย์ เราไม่รู้ว่ารูปแบบแบบแผนรายงานที่ถูกต้องเป็นอย่างไร เราจะแก้ปัญหายังไงเพื่อให้ทำรายงานเสร็จ เราก็จะไปขอตัวอย่างรายงานจากรุ่นพี่ หรือจากอาจารย์ แล้วนำมันมาปรับปรุงเป็นแบบอย่างให้ฉบับของเรา แต่พอเราโตขึ้นมาก ก็จะมีความเคยชิน มีประสบการณ์ สามารถเขียนรายงานได้โดยไม่ต้องพึ่งตัวอย่างอีกต่อไป

ในทำนองเดียวกัน หัวหน้าให้งานลูกทีมไปทำ ถ้าเราอยากให้มั่นใจว่าลูกทีมทำงานมาถูกต้องโดนใจ ในบางเนื้องาน เราก็จะมีเทคนิคสอนงานลูกทีม โดยการให้ตัวอย่างไว้เทียบเคียง เทคนิคเดียวกันนี้ ก็สามารถใช้ได้ผลกับน้อง GPT-4o เช่นกัน

##### ตัวอย่างที่ 2
เวลาทำงานเกี่ยวกับการคิดวิเคราะห์ อย่างเช่นให้เด็กทำโจทย์เลข เราก็จะชอบเจอเด็กคิดในหัว ชอบหาผลลัพธ์ให้ได้ในขั้นตอนเดียว แต่เรื่องแบบนี้ไม่ได้เกิดแค่กับในเด็ก คนส่วนมากก็เป็นเช่นนั้น พอเจอโจทย์ยากๆเข้า ก็แก้ไม่ออก งมอยู่ที่เดิมเป็นชั่วโมง แล้วมีเทคนิคอะไรช่วยได้บ้าง ก็หนีไม่พ้น การทดออกมาก การค่อยๆคิดเป็นลำดับขั้นตอน เขียนความคิดลงในกระดาษ อย่าไปเก็บทุกอย่างไว้ในหัวเรา เหมือนเวลาต้องคำนวนเลขหลายหลัก ถ้าเราทดเลขไว้ในหัวเยอะๆ ก็จะชอบคิดผิด แต่เราทดลงในกระดาษ ก็ผิดเหมือนกัน แต่โอกาสผิดน้อยกว่า ดังนั้นทดในกระดาษเถอะ ไม่ต้องทดสอบความสามารถในการทดในหัวของเราเสมอไป

น้อง GPT-4o ก็ได้ประโยชน์จากเทคนิคนี้เช่นกัน จะเสียแต่ว่าน้องเป็นเหมือนคนทั่วไปเลย อยู่ๆให้โจทย์มา น้องก็จะชอบคิดในหัว แล้วกระโดดมาที่ผลลัพธ์ แล้วก็คิดผิด ดังนั้นเราก็ต้องช่วยเตือนว่าห้ามคิดในหัวนะ ให้ทดลำดับขั้นตอนการคิดออกมา แล้วถึงค่อยให้ผลลัพธ์

##### ตัวอย่างที่ 3
อันนี้เป็นความเคยชินที่เราชอบลืมตัวกัน เวลาเราทำงานกับลูกทีมที่ ใสซื่อมากๆ ทำงานตามคำสั่งแบบตรงเฉ็ง เช่นเรามอบหมายงาน "ให้หาว่าข้อความตัวนี้ ถูกกล่าวถึงในหน้าไหนของหนังสื่อ" ถ้าข้อความมีอยู่จริงในหนังสือ เราก็ไม่ต้องเป็นกังวลว่าลูกทีมจะทำงานพลาด แต่เมื่อไหร่ก็ตามที่ข้อความไม่ได้มีอยู่จริงในหนังสือ คิดว่าจะเกิดอะไรขึ้น ลูกทีมมาบอกว่า "มันไม่มีอยู่จริง" เผอิญว่าโลกเราไม่ได้เป็นเช่นนั้นเสมอไป สิ่งที่ลูกทีมคนนี้คิดคือ งานคือต้องหาตัวเลขมาให้ไม่ว่าด้วยวิธีอะไร แล้วสุดท้าย ก็ลงเอยด้วยการ มั่วเลขหน้าขึ้นมา น้อง GPT-4o เราดันเป็นเหมือนลูกทีมคนนี้เลย TT

เอาละ แล้วเราจะแก้ปัญหานี้อย่างไร ก็ต้องกลับมาดูที่วิธีการสื่อสาร เราจะด่วนสรุปว่าเรื่องปกติของเรา จะเป็นเรื่องปกติของทุกคนไม่ได้ ฉะนั้นในกรณีนี้ เราก็ต้องสั่งงานให้ชัดเจน เช่น "ให้หาว่าข้อความตัวนี้ ถูกกล่าวถึงในหน้าไหนของหนังสื่อ ถ้าไม่มี ก็บอกว่าไม่มี" ถ้าจะให้สรุปเป็นเทคนิคการสื่อสาร ก็คงจะเป็น อย่ามองข้ามบริบท การให้คำอธิบายว่างานที่ให้ ทำไปทำไม ทำเพื่ออะไร จะช่วยให้น้องๆ ทำออกมาได้ถูกต้องตามวัตถุประสงค์

ถ้าให้ลองคิดขำๆนะ เวลาเราทำงาน "ให้หาว่าข้อความตัวนี้ ถูกกล่าวถึงในหน้าไหนของหนังสื่อ" อาจจะตีความได้ 2 แบบก็เป็นได้ ไม่ "เราต้องการตัวเลข หาตัวเลขนั้นมา" ก็ "เราต้องการเช็คว่าผู้เขียนคนนี้ อ้างอิงข้อความที่มีอยู่จริงไหม ถ้ามันมีอยู่จริง ก็ควรมีเลขหน้ามาอ้างอิงได้" เอาละ ถ้าเข้าใจแล้ว ลองสั่งการน้อง GPT-4o ให้ชัดเจนขึ้นดู ลองบอกบริบทไปด้วย นึกอะไรออก ใส่ไปให้หมด เอาให้ชัดเจนที่สุด

---
ไม่รู้มีใครคิดเหมือนกันไหม ว่าเวลาเราให้งานกับ GPT-4o มันเหมือนกับคุยกับเด็กจบใหม่ที่พึ่งรับเข้ามาในบริษัทจริงๆนะ

เอาละ แสดงความยินดีด้วย ถ้าคุณเข้าใจแล้วว่าการสื่อสารที่ดี มีผลยังไงกับ GPT-4o ตอนนี้คุณก็จะได้ก้าวขาข้างหนึ่งเป็น Prompt Engineering แล้ว

หา ยังไงกัน ไม่เห็นมีคำศัพท์เท่ๆ โผล่มาเลย

ใจเย็นๆ เรากำลังไปถึงตรงนั้นกัน (บอกตัวผู้เขียนเองแหละ)

มาลองไปกันทีละตัวอย่างกัน
- การมีตัวอย่างประกอบการสั่งงาน - เบื้องต้นของ one-shot, few-shot prompting เป็นกลยุทธ์ที่ทำให้ GPT-4o คุ้นเคยกับคำถาม และวิธีรับมือกับคำตอบ โดยการให้คู่ตัวอย่างของคำถาม และคำตอบ ที่เกี่ยวข้องกับงานที่ให้
	- ซึ่งมาลองสังเกตดู ไม่ต่างกับเวลาเราสอนงานคนเลยนะ การมีตัวอย่าง ก็เป็นทริคในการเรียนรู้ที่ใช้ได้ในหลายๆเหตุการณ์เลย
	- มีข้อสังเกตุคือ เวลายกตัวอย่าง เพียงยกตัวอย่างแค่คำตอบ เมื่อมีเวลาน้อย ก็สามารถเพิ่มคุณภาพได้ แต่ถ้าให้ดียิ่งกว่า ก็ควรมาเป็นคู่ของ คำถามและคำตอบ
- การทดออกมาเวลาให้โจทย์ที่เกี่ยวกับการคิดวิเคราะห์ - ที่มาของ Chain-of-Thought (CoT) Prompting เป็นกลยุทธ์ที่ทำให้ GPT-4o รับมือกับโจทย์โดยการคิดหลายขั้นตอน ที่ทั้งยาวและดูช้า แทนที่การคิดให้ได้ภายในขั้นตอนเดียว ที่ทั้งสั้นและเร็วกว่า(แต่ก็มีโอกาสผิดได้มากกว่า) และดันเป็นค่าตั้งต้นไปโดยปริยาย
	- ฟังดูคล้ายๆเราเลยนะ แบบคิดเลขก็ชอบทดในใจ สุดท้ายคิดผิด เหมือน 25x25 = 225 XD

นอกจากกลยุทธ์ที่ยกมาสองอัน ปัจจุบันก็มีของใหม่มาอีกเพียง เช่น Least-to-Most Prompting, Generated Knowledge, Prompt Paraphrasing, Self-Calibration

แต่เหมือนทุกครั้งที่ย้ำตลอดมา แทนที่จะมอง AI เป็นสิ่งแปลกใหม่ เป็นเครื่องมือที่ไม่เคยเห็นมาก่อน ให้ลองมองเป็น**คน** **คน**ที่เก่งกลางๆที่ทำได้ทุกเรื่องแทน แล้วเวลาเรามอบหมายงานให้ ก็มองซะว่าเขาเป็นเด็กจบใหม่ เขามีความสามารถ แต่จะดึงความสามารถออกมาได้ เราก็ต้องชี้นำเขาให้เป็น สามารถสื่อสารให้ชัดเจน ลองหยิบเทคนิค กลยุทธ์ ต่างๆ ที่ใช้สอนคน ลองเอามาใช้กับ AI ดู แล้วจะพบว่า ChatGPT ไม่ได้ใช้ยากเท่าที่คิด และมันทำได้มากกว่าที่เรารู้

## การนำไปใช้
พออ่านมาถึงจุดนี้ เริ่มสั่งงาน GPT-4o เป็น ก็ต้องนำไปประยุกต์ใช้ช่วยงานละ แต่เราจะไปทีละขั้นกัน แบ่งตามระดับการอัตโนมัติ

> ทำไมต้องแบ่งตามระดับการอัตโนมัติ เพราะพื้นฐานที่ต้องรู้ของทั้งคู่เหมือนกัน ต่างกันที่ คุณ ctrl+c ctrl+v เอง หรือคุณเขียนสคริปต์ให้ AI รันให้

#### ระดับ ctrl+c ctrl+v
คือระดับทั่วไป เวลาใช้พวก ChatGPT เช่นเวลามีคำถาม ก็พิมพ์ลงไป แล้วถ้าได้คำตอบที่ถูกใจก็ก็อปไปวางในรายงาน หรือไม่ก็คัดล็อกบทความหรือบันทึกการประชุม แล้วมาวางใน ChatGPT ให้มันช่วยสรุปให้

ในระดับนี้ ถ้าอยากได้ผลลัพท์ที่ใช้การใช้ ก็หนีไม่พ้นการเขียนคำสั่งที่มีคุณภาพ อย่างการช่วยสรุปบทความ บางครั้งก็ได้สรุปที่ย่อเกิน หรือไม่ก็สรุปที่ยาวจนไม่ต่างไปจากบทความดังเดิม ถ้าเจอปัญหาเช่นนี้ อย่าพึ่งคิดเสียว่า ChatGPT ไร้ความสามารถ ลองย้อนกลับไปดูคำสั่งของเราดู ไม่แน่คำสั่งเราอาจกำกวมเอง เราอาจจะไม่ได้ระบุความยาวของบทสรุป ไม่ได้บอกว่าสรุปให้ใครอ่าน อย่าลืมว่า ChatGPT อ่านใจเราไม่ได้นะ

แต่บางทีจะมานั่งเขียนคำสั่งที่ดี สำหรับงานบางงานก็อาจะไม่คุ้มค่าต่อเวลา เปรียบเสมือนบางงานที่เราก็หมอบหมายให้รุ่นน้องทำได้ แต่บางงานยังไงก็ต้องเป็นเรา ต้องลองหาจุดสมดุลดู ถ้าเป็นงานที่เราทำซ้ำๆเป็นประจำ อย่างเช่นคุณมี**ธุรกิจขายของออนไลน์** แล้วต้องมานั่งอ่านอีเมล์ วันละ 100 ฉบับทุกวัน ฉบับนึง สมมุติว่าอ่านฉบับละ 3 นาที เพียงเท่านี้ คุณก็หมดเวลาไปแล้ว 5 ชั่วโมง เจอแบบนี้ลองเปิดใจให้ ChatGPT ช่วยอ่าน (เดี๋ยวกล่าวถึงเรื่องความปลอดภัยอีกทีนะ) อาจจะให้งานง่ายๆก่อน เช่น แยกว่าวัตถุประสงค์ ระหว่าง**ขอเปลี่ยนที่อยู่จัดส่ง** กับ**อื่นๆ** เอาแค่ 2 อย่างก่อน คุณก็เขียนคำสั่งไป เช่น

- ทำอะไร - นี้คืออีเมล์ ของลูกค้าที่ใช้บริการ จงวิเคราห์ และระบุวัตถุประสงค์ของอีเมล์นี้ โดยให้ระบุได้เพียง 2 อย่าง "ขอเปลี่ยนที่อยู่จัดส่ง" กับ "อื่นๆ" 
- ขยายความ - "ขอเปลี่ยนที่อยู่จัดส่ง" คือเมื่ออีเมล์ต้องการ... กับ "อื่นๆ" คือเมื่อ....
- ทดออกมา - เวลาวิเคราะห์ ให้ทดลงมาด้วยว่า ใจความสำคัญของอีเมล์ ถูกกล่าวถึงตรงไหนบ้าง แต่ละจุดต้องการสื่ออะไร ก่อนให้คำตอบสุดท้าย

ถ้าคุณจูนจน ChatGPT ทำผลลัพธ์ได้ดี คุณอาจจะช่วยกรองจดหมายครึ่งหนึ่ง ให้ใช้เวลาอ่านเหลือแค่ 30 วินาที แล้วได้เวลาคืนมา 2 ชั่วโมง แล้วลองคิดดู ถ้าคนในทีม ได้เวลาคืนมาแบบนี้เช่นกัน คุณจะเอาเวลาไปทำอะไรให้เกิดประโยชน์เพิ่มเติมได้อีกบ้าง

จุดสำคัญสำหรับระดับนี้คือ คุณไม่ได้ต้องเป็น Programmer หรือ Software Engineer หรือเขียนโค๊ดได้ เพียงคุณเรียนรู้ที่จะสื่อสารให้มีคุณภาพ (คุยให้รู้เรื่อง 😉) คุณก็สามารถนำมาใช้ได้

#### ระดับเขียนสคริปต์ได้
คือระดับที่รู้จัก API เขียนโค๊ด เขียนสคริปต์ได้ ถ้าคุณอยู่จุดนี้แสดงว่า คุณก็ยังคงต้องเขียนคำสั่งให้เป็นเหมือนระดับก่อนหน้า แต่แทนที่จะมานั่ง ctrl+c ctrl+v เอง คุณก็จะเขียนสคริป ใช้ API ดึงข้อมูลจากต้นทาง ไปส่งให้ GPT-4o โดยตรง และนำผลลัพธ์ไปแสดงซักที่

ลองเทียบกับตัวอย่างเดิม **ธุรกิจขายของออนไลน์** แต่แทนที่จะมีอีเมล์เข้ามาวันละ 100 กลายเป็นวันละ 1,000 หรือ 10,000 จะให้มานั่ง ctrl+c ctrl+v ก็คงไม่เสร็จแน่ ก็ต้องอัพเกรด ให้ Software Engineer สร้างโปรแกรมที่ดึงอีเมล์ แล้วส่งไป GPT-4o แล้วนำผลลัพธ์ไปแสดงในโปรแกรม หลังจากนั้นจะต่อยอด ให้แสดงได้ว่า เปลี่ยนที่อยู่จัดส่ง จากไหนไปไหน ออเดอร์ไหน ก็ส่งตัวอีเมล์ไปให้ GPT-4o ช่วยดึงข้อมูลออกมาให้ แล้วก็ทำโปรแกรมชี้ให้เห็นว่าข้อความแต่ละส่วนดึงมาจากไหน แล้วสุดท้ายก็ให้คนตรวจทานไวๆ และเป็นคนตัดสินใจ

สิ่งที่โมเดลอย่าง GPT-4o เข้ามาเปลี่ยนได้อย่างมีนัยยะสำคัญ ไม่ใช่การเขียนโปรแกรม แต่เป็นการทำให้โปรแกรมเข้าถึงภาษามนุษย์ได้อย่างง่ายดาย สามารถแปลงข้อมูลที่ไม่มีโครงสร้าง อย่างประโยคที่เราพูดคุยกัน ให้กลายเป็นข้อมูลที่มีโครงสร้าง ที่คอมพิวเตอร์เข้าใจได้ แล้วนำไปต่อยอดอย่างอื่นได้ กำแพงระหว่างคอมพิวเตอร์ และมนุษย์ก็ได้แคบลงไปอีกขั้น

โมเดลแบบ GPT-4o เองจะทำงานได้ดี ไม่ดี ก็ขึ้นกับข้อมูลที่ส่งให้ ลองท้าทายสกิลการสื่อสารดู แล้วจะพบว่าดึงความสามารถของ GPT-4o ออกมาไม่ได้ยากอย่างที่คิด

## ใช้ LLM อย่างที่มันถูกฝึกมา
เราคุยกันมาตลอดบทความว่า ให้มอง LLM เป็นเหมือนคน แต่สุดท้ายแล้วก็ต้องยอมรับความจริงอย่างที่ว่า มันก็เป็นเพียงโมเดลภาษาขนาดใหญ่ ที่เรียนรู้ด้วยข้อมูลคนจำนวนมาก มันเลยเรียนรู้ที่จะทำงานเปรียบเสมือนคน

เรามาว่ากันต่อ ว่า LLM ต่างจากคนตรงไหนบ้าง 

LLM โดยส่วนใหญ่ ไม่ได้ฝึกด้วยข้อความแบบที่เราพูดคุยกันปกติ แต่เป็นข้อความที่ปรับบางส่วนเพื่อให้ง่ายต่อโมเดลในการเรียนรู้เช่น

- ใช้ xml tag (`</>`) ในการช่วยแบ่งข้อความเป็นสัดส่วน และชี้ความสัมพันธ์ เช่น ถ้าเรายกตัวอย่าง ข้อความที่ประกอบด้วยคำถาม และคำตอบ
	- "<span style={{background: 'rgb(var(--color1) / 0.5'}}>ตัวอย่างคู่คำถามคำตอบ</span> <span style={{background: 'rgb(var(--color2) / 0.5'}}>นี้คือคำถาม 1+1 คือเท่าไหร่</span> <span style={{background: 'rgb(var(--color4) / 0.5'}}>คำตอบของคำถามคือ 2</span>" คือสิ่งที่เราเห็น แต่ LLM อาจจะเห็นเป็น
		- "<span style={{background: 'rgb(var(--color1) / 0.5'}}>ตัวอย่างคู่คำถามคำตอบ นี้คือคำถาม 1+1 คือเท่าไหร่ คำตอบของคำถามคือ 2</span>"
		- "<span style={{background: 'rgb(var(--color1) / 0.5'}}>ตัวอย่างคู่คำถามคำตอบ นี้คือคำถาม 1+1 คือเท่าไหร่</span> <span style={{background: 'rgb(var(--color2) / 0.5'}}>คำตอบของคำถามคือ 2</span>" 
		- "<span style={{background: 'rgb(var(--color1) / 0.5'}}>ตัวอย่างคู่คำถามคำตอบ </span> <span style={{background: 'rgb(var(--color2) / 0.5'}}>นี้คือคำถาม 1+1 คือเท่าไหร่ คำตอบของคำถามคือ 2</span>" 
	- ถ้าอยากให้โมเดลเห็นเหมือนเรา ก็ต้องทำคล้ายกับข้อมูลที่ใช้ฝึก เช่น
		- "<span style={{background: 'rgb(var(--color1) / 0.5'}}>ตัวอย่างคู่คำถามคำตอบ &lt;examples><span style={{background: 'rgb(var(--color2) / 0.5'}}>&lt;question>นี้คือคำถาม 1+1 คือเท่าไหร่&lt;/question></span><span style={{background: 'rgb(var(--color4) / 0.5'}}>&lt;answer>คำตอบของคำถามคือ 2&lt;/answer></span>&lt;/examples></span>"
- ใช้ markdown (#) ในการบ่งบอกความสำคัญ หากไปลองศึกษาดู เราจะเจอตัวอักษรพิเศษ ที่แทนที่ดังนี้ `#` คือ **header 1** หรือ `##` คือ **header 2** ซึ่งเมื่อนำมาใช้ จะช่วยให้ LLM สามารถแยกแยะลำดับความสำคัญของ หัวข้อและเนื้อความที่ตามมาได้ถูกต้องเหมือนกับที่เราเข้าใจ



ดังนั้นหากจะให้มั่นใจว่า LLM ตีความได้ดังที่เราต้องการ อย่าลืมปัจจัยนี้ด้วยละ
## ความปลอดภัย
เรามาชวนให้ลองใช้ Gen AI ให้เป็นแล้ว ก็ต้องกล่าวถึง หัวข้อความปลอดภัยด้วย

> ถ้าให้สรุปสั้นๆเลยนะ ให้ความสำคัญและระมัดระวัง **เทียบเท่ากับ** เทคโนโลยีอื่นๆที่ใช้อยู่

เราควรที่จะต้องใช้ LLM ด้วยความระมัดระวัง **ไม่มากไปกว่า หรือน้อยไปกว่า** เวลาใช้ Facebook Google X(Twitter) Shopee Lazada 

จริงอยู่ที่ LLM ดูทรงพลัง แต่การโมเดลภาษาเหล่านี้ได้ข้อมูลจากเราไปได้ ก็ไม่ใช่เพราะมันมีญาณทิพ มันรู้ได้ก็เพราะเราให้ข้อมูลมันไป ไม่ว่าจะโดยทางตรง เช่นเคยกล่าวถึงเวลาแชทคุยกับมัน หรือทางอ้อมเช่นมันคาดเดาจากข้อมูลอื่นที่เราเคยให้ไป ซึ่งนี้เป็นหลักการคล้ายกันกับที่ Facebook Youtube ยิง Ads ใส่เรา จู่ๆเขาก็ไม่รู้หรอกว่าเราอยากซื้อของอะไร แต่เพราะเราดันปล่อยข้อมูลเหล่านี้ลงในอินเตอร์เน็ตโดยไม่รู้ตัว

เวลานำ LLM ไปใช้ในงาน ก็ควรศึกษาแนวปฏิบัติ ยึดตามพระราชบัญญัติคุ้มครองข้อมูลส่วนบุคคล หรือ PDPA เป็นแนวทาง ถ้าคุณเป็นผู้ใช้ ก็ควรสังเกตและให้ข้อมูลเฉพาะที่โปรแกรมจำเป็นต้องรับรู้ ส่วนถ้าคุณเป็นคนออกแบบโปรแกรม ก็ควรขอเฉพาะข้อมูลที่จำเป็นต่อการทำงานของโปรแกรม ถ้าบางครั้งต้องรับมือกับข้อความที่อาจมีข้อมูลส่วนบุคคลติด(PII) มาด้วย ก็ควรทำการลบหรือเซ็นเซอร์ PII ก่อนนำไปคำนวนผ่าน LLM หรือโปรแกรมอื่นๆ 

> หากใครสนใจเรื่องการลบหรือเซ็นเซอร์ข้อมูลส่วนบุคคลที่ติดมากับข้อความ ลองเสริชหา "Data Redaction"

# สรุป